{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionally align representations across neural networks\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/qihongl/demo-nnalign/blob/master/demo-nnalign.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "- This is a toy demo for <a href=\"http://arxiv.org/abs/1811.11684\">Lu et al. 2018</a>. \n",
    "<br>\n",
    "- Here's the <a href=\"https://github.com/qihongl/nnsrm-neurips18\">repo</a> for that project, which contains the code for the experiments/simulations documented in the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a one sentence summary of the result: \n",
    "- different neural networks with the same learning experience acquire representations of the same \"shape\"\n",
    "\n",
    "The goal of this script is to demonstrate the point above, by...\n",
    "- training two networks on the same task \n",
    "- then show that they are mis-aligned \n",
    "- align their representations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get brainiak \n",
    "!pip install pip==9.0.1\n",
    "!pip install git+https://github.com/brainiak/brainiak\n",
    "!pip install keract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from brainiak.funcalign.srm import SRM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs, make_classification\n",
    "from keract import get_activations\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "sns.set(style='white', context='talk', palette='colorblind')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Make some simulated data\n",
    "\n",
    "First of all, we need generate a learning problem to train some neural networks. In this notebook, we will use a \"noisy XOR task\". The figure below shows the training set. The test set is independently generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xor_data(n_samples=200):\n",
    "    center_locs = np.array([[1,1],[-1,-1],[1,-1],[-1,1]])\n",
    "    cluster_std = .4\n",
    "    n_features = 2\n",
    "    n_classes = 2\n",
    "    # gen pts \n",
    "    coords, cluster_ids = make_blobs(\n",
    "        n_features=n_features, \n",
    "        n_samples=n_samples, \n",
    "        shuffle=False,\n",
    "        cluster_std=cluster_std, \n",
    "        centers=center_locs\n",
    "    )\n",
    "    points_per_class = n_samples // n_classes\n",
    "    class_labels = np.repeat([0,1], points_per_class)\n",
    "    return coords, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some XOR data\n",
    "n_examples = 200\n",
    "x_train, y_train = make_xor_data(n_examples)\n",
    "x_test, y_test = make_xor_data(n_examples)\n",
    "\n",
    "# plot the data \n",
    "cur_palette = sns.color_palette(n_colors=2)\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize=(6,5))\n",
    "for i, y_val in enumerate(np.unique(y_train)): \n",
    "    ax.scatter(\n",
    "        x_train[y_val == y_train,0],x_train[y_val == y_train,1], \n",
    "        color=cur_palette[i], \n",
    "    )\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_title('the training data')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train some neural networks on a common training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help funcs\n",
    "hidden_layer_name = 'hidden'\n",
    "\n",
    "def get_net(n_hidden): \n",
    "    \"\"\"define a simple neural network with some hidden units\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_hidden, input_dim=2, activation='tanh',name=hidden_layer_name))\n",
    "    model.add(Dense(1, activation='sigmoid',name='output'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model \n",
    "\n",
    "def get_hidden_act(model, data):\n",
    "    \"\"\"get neural network activity\"\"\"\n",
    "    acts = get_activations(model, data)\n",
    "    for layer_name in acts.keys():\n",
    "        if hidden_layer_name in layer_name: \n",
    "            return acts[layer_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params \n",
    "n_hidden = 50\n",
    "# training params\n",
    "batch_size = 64\n",
    "shuffle=True\n",
    "n_nets = 2\n",
    "n_epochs = 500\n",
    "\n",
    "# train several models  \n",
    "models = []\n",
    "records = []\n",
    "for i in range(n_nets): \n",
    "    model_i = get_net(n_hidden)\n",
    "    record_i = model_i.fit(\n",
    "        x_train, y_train, epochs=n_epochs, \n",
    "        validation_data = (x_test,y_test),\n",
    "        batch_size=batch_size, shuffle=shuffle, verbose=0\n",
    "    )\n",
    "    models.append(model_i)\n",
    "    records.append(record_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the classification accuracy for both the training set and the test set, just to confirm that these network learned the task reasonably. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curves\n",
    "f, axes = plt.subplots(1,n_nets, figsize=(13,4),sharey=True)\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.plot(records[i].history['acc'],label='train')\n",
    "    ax.plot(records[i].history['val_acc'],label='test')\n",
    "    ax.set_title(f'Learning curve, network {i+1}')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(frameon=False, bbox_to_anchor=(.7, .6), loc=2, borderaxespad=0)\n",
    "    \n",
    "sns.despine()\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Some observations\n",
    "\n",
    "#### Observation 1: \"representational similarity matrix (RSM)\" are similar across networks\n",
    "\n",
    "\n",
    "The following figure shows within-subject RSM, which compares the similarity between ... \n",
    "- the evoked response of stimulus i in one network \n",
    "- the evoked response of stimulus j in **the same** network \n",
    "\n",
    "The result shows that the two networks learn basically the same \"representational similarity structure\". That is, the relation between stimulus i and stimulus j is similar across the two networks. We call this the shared representational structure across these two networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the network and get its hidden layer activity \n",
    "hidden_act_mats = [get_hidden_act(model, x_test) for model in models]\n",
    "within_subject_RSMs = [np.corrcoef(h_i) for h_i in hidden_act_mats]\n",
    "\n",
    "f,axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "for i in range(n_nets):\n",
    "    axes[i].imshow(within_subject_RSMs[i], cmap='viridis')\n",
    "    axes[i].set_xlabel('stimuli id')\n",
    "    axes[i].set_ylabel('stimuli id')\n",
    "    axes[i].set_title(f'Within network RSM, network {i+1}')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation 2: however, the same stimulus evokes different response patterns across the two networks\n",
    "\n",
    "The following figure shows the intersubject RSM in their native spaces, which compares ... \n",
    "- the evoked hidden activity pattern of stimulus i from one network \n",
    "- the evoked hidden activity pattern of stimulus j from **another** network \n",
    "\n",
    "You can see that the following \"intersubject\" RSM doesn't reflect the representational similarity structure that's shared across the two networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_subject_RSM_native = np.corrcoef(\n",
    "    hidden_act_mats[0],hidden_act_mats[1]\n",
    ")[:n_examples,n_examples:]\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(6,5))\n",
    "\n",
    "ax.imshow(inter_subject_RSM_native, cmap='viridis')\n",
    "ax.set_xlabel('stimuli id')\n",
    "ax.set_ylabel('stimuli id')\n",
    "ax.set_title('intersubject RSM, native spaces')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** So what's similar across these two networks? How do these two networks encode the same similarity structure with different patterns of neural activity? \n",
    "\n",
    "**One answer:** We observed that the main reason is that they are misaligned. That is to say, their representational structures really have the same \"shape\", but oriented differently. Empirically, we show that a rigid-body-transformation (i.e. an orthogonal matrix) is usually enough to align them. \n",
    "\n",
    "In the two subject case, we can solve the optimal orthogonal transformation by solving the procrustes problem. However, in the more general case of aligning n networks, we can use the shared response model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Align representations across networks with the shared response model (SRM)\n",
    "\n",
    "The following code blocks provide a minimal example of the SRM alignment pipeline. \n",
    "\n",
    "*In practice, the number of components for SRM can be tuned like how you tune PCA (e.g. measure variance explained). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "# get neural network activity matrices ... \n",
    "h_act_train = [get_hidden_act(model, x_train).T for model in models]\n",
    "h_act_test = [get_hidden_act(model, x_test).T for model in models]\n",
    "\n",
    "# step 2: normalize the data \n",
    "for i in range(n_nets): \n",
    "    sscalar = StandardScaler()\n",
    "    sscalar.fit(h_act_train[i])\n",
    "    h_act_train[i] = sscalar.transform(h_act_train[i])\n",
    "    h_act_test[i] = sscalar.transform(h_act_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: fit SRM\n",
    "n_components = n_hidden\n",
    "srm = SRM(features=n_components)\n",
    "# train SRM on the training set \n",
    "h_act_train_shared = srm.fit_transform(h_act_train)\n",
    "# use the trained SRM to transform the test set activity\n",
    "h_act_test_shared = srm.transform(h_act_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once aligned, the intersubject RSM is become similar to the within-subject RSM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute inter-subject RSM in for the transformed activities (in the shared space)\n",
    "inter_subject_RSM_shared = np.corrcoef(\n",
    "    h_act_test_shared[0].T,h_act_test_shared[1].T\n",
    ")[:n_examples,n_examples:]\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(6,5))\n",
    "\n",
    "ax.imshow(inter_subject_RSM_shared, cmap='viridis')\n",
    "ax.set_xlabel('stimuli id')\n",
    "ax.set_ylabel('stimuli id')\n",
    "ax.set_title('intersubject RSM, shared space')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put the three matrices ... \n",
    "- intersubject RSM in the shared space \n",
    "- averaged within-subject RSM\n",
    "- intersubject RSM in the native space\n",
    "\n",
    "... side by side. This is similar to Fig 2B in the paper. \n",
    "\n",
    "Again the point is that, **once aligned in some common space, the intersubject RSM is similar to the within-subject RSM**. In other words, although both stimulus i and stimulus j evoke different responses across these two networks, the relation between stimulus i and stimulus j is represented similarity (across these two networks). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the 3 matrices side by side \n",
    "titles = ['iRSM, shared space', 'wRSM, native spaces', 'iRSM, native spaces']\n",
    "mats = [\n",
    "    inter_subject_RSM_shared, \n",
    "    np.mean(within_subject_RSMs,axis=0), \n",
    "    inter_subject_RSM_native\n",
    "]\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(13,5))\n",
    "for i,ax in enumerate(axes): \n",
    "    ax.imshow(mats[i], cmap='viridis')\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xlabel('stimuli id')\n",
    "    ax.set_ylabel('stimuli id')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Thank you very much to your time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
